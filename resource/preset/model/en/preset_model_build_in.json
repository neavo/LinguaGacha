[
    {
        "id": "preset-sakura",
        "type": "PRESET",
        "name": "SakuraLLM",
        "api_format": "SakuraLLM",
        "api_url": "http://127.0.0.1:8080",
        "api_key": "no_key_required",
        "model_id": "no_model_required",
        "network_config": {
            "custom_headers": {},
            "custom_body": {}
        },
        "thresholds": {
            "input_token_limit": 384,
            "output_token_limit": 768,
            "rpm_limit": 0,
            "concurrency_limit": 0
        },
        "thinking": {
            "level": "OFF"
        },
        "generation": {
            "temperature": 0.95,
            "temperature_custom_enable": false,
            "top_p": 0.95,
            "top_p_custom_enable": false,
            "presence_penalty": 0.0,
            "presence_penalty_custom_enable": false,
            "frequency_penalty": 0.0,
            "frequency_penalty_custom_enable": false
        }
    },
    {
        "id": "preset-google",
        "type": "PRESET",
        "name": "Google",
        "api_format": "Google",
        "api_url": "https://generativelanguage.googleapis.com",
        "api_key": "no_key_required",
        "model_id": "gemini-2.0-flash",
        "network_config": {
            "custom_headers": {},
            "custom_body": {}
        },
        "thresholds": {
            "input_token_limit": 768,
            "output_token_limit": 4096,
            "rpm_limit": 0,
            "concurrency_limit": 0
        },
        "thinking": {
            "level": "OFF"
        },
        "generation": {
            "temperature": 0.95,
            "temperature_custom_enable": false,
            "top_p": 0.95,
            "top_p_custom_enable": false,
            "presence_penalty": 0.0,
            "presence_penalty_custom_enable": false,
            "frequency_penalty": 0.0,
            "frequency_penalty_custom_enable": false
        }
    },
    {
        "id": "preset-openai",
        "type": "PRESET",
        "name": "OpenAI",
        "api_format": "OpenAI",
        "api_url": "https://api.openai.com/v1",
        "api_key": "no_key_required",
        "model_id": "gpt-4.1-mini",
        "network_config": {
            "custom_headers": {},
            "custom_body": {}
        },
        "thresholds": {
            "input_token_limit": 768,
            "output_token_limit": 4096,
            "rpm_limit": 0,
            "concurrency_limit": 0
        },
        "thinking": {
            "level": "OFF"
        },
        "generation": {
            "temperature": 0.95,
            "temperature_custom_enable": false,
            "top_p": 0.95,
            "top_p_custom_enable": false,
            "presence_penalty": 0.0,
            "presence_penalty_custom_enable": false,
            "frequency_penalty": 0.0,
            "frequency_penalty_custom_enable": false
        }
    },
    {
        "id": "preset-deepseek",
        "type": "PRESET",
        "name": "DeepSeek",
        "api_format": "OpenAI",
        "api_url": "https://api.deepseek.com",
        "api_key": "no_key_required",
        "model_id": "deepseek-chat",
        "network_config": {
            "custom_headers": {},
            "custom_body": {}
        },
        "thresholds": {
            "input_token_limit": 768,
            "output_token_limit": 4096,
            "rpm_limit": 0,
            "concurrency_limit": 0
        },
        "thinking": {
            "level": "OFF"
        },
        "generation": {
            "temperature": 0.95,
            "temperature_custom_enable": false,
            "top_p": 0.95,
            "top_p_custom_enable": false,
            "presence_penalty": 0.0,
            "presence_penalty_custom_enable": false,
            "frequency_penalty": 0.0,
            "frequency_penalty_custom_enable": false
        }
    },
    {
        "id": "preset-anthropic",
        "type": "PRESET",
        "name": "Anthropic",
        "api_format": "Anthropic",
        "api_url": "https://api.anthropic.com",
        "api_key": "no_key_required",
        "model_id": "claude-3-5-haiku",
        "network_config": {
            "custom_headers": {},
            "custom_body": {}
        },
        "thresholds": {
            "input_token_limit": 768,
            "output_token_limit": 4096,
            "rpm_limit": 0,
            "concurrency_limit": 0
        },
        "thinking": {
            "level": "OFF"
        },
        "generation": {
            "temperature": 0.95,
            "temperature_custom_enable": false,
            "top_p": 0.95,
            "top_p_custom_enable": false,
            "presence_penalty": 0.0,
            "presence_penalty_custom_enable": false,
            "frequency_penalty": 0.0,
            "frequency_penalty_custom_enable": false
        }
    }
]
